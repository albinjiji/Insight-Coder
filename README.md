# InsightCoder

**AI-powered coding assistant** for the browser. InsightCoder helps you write, debug, and learn code with clear explanations, syntax-highlighted snippets, and a chat UX that supports multi-turn **clarifications**.

[![Next.js](https://img.shields.io/badge/Next.js-14%2B-black)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-Strict-blue)](https://www.typescriptlang.org/)
[![Redux Toolkit](https://img.shields.io/badge/State-Redux%20Toolkit-764abc)](https://redux-toolkit.js.org/)
[![Google Gemini](https://img.shields.io/badge/AI-Gemini-0b57d0)](https://ai.google.dev/)

---

## âœ¨ Features

- **Chat UX** with history, auto-titles, delete chat, and â€œNew Chatâ€
- **Code-aware answers** (Gemini 2.5 Flash with fallback to 1.5 Flash)
- **Classification gate** (filters non-coding queries with a friendly message)
- **Clarify flow**: asks for missing context; supports chained clarifications
- **Markdown + syntax highlighting** (react-markdown + Prism oneDark)
- **Redux Toolkit** state
- **Dark, clean UI** with CSS Modules

---

## ğŸ–¼ Tech Stack

- **Frontend**: Next.js (App Router), React 18, TypeScript, CSS Modules  
- **State**: Redux Toolkit (slice + async thunk)  
- **AI**: `@google/genai` (Gemini) via a Next.js API route  
- **Markdown**: `react-markdown` + `react-syntax-highlighter` (Prism oneDark)  
- **IDs**: `uuid` (v4)

---

## ğŸ“ Project Structure

```text
.
â”œâ”€ .env.local                  # GEMINI_API_KEY lives here (not committed)
â”œâ”€ package.json
â”œâ”€ tsconfig.json
â”œâ”€ next.config.ts
â”œâ”€ postcss.config.mjs
â”œâ”€ tailwind.config.ts          # if you use Tailwind (otherwise omit)
â”œâ”€ README.md
â”œâ”€ LICENSE
â””â”€ src/
   â”œâ”€ app/
   â”‚  â”œâ”€ api/
   â”‚  â”‚  â””â”€ gemini/
   â”‚  â”‚     â””â”€ route.ts        # Next.js API route â†’ calls Google Gemini
   â”‚  â”œâ”€ home-page/
   â”‚  â”‚  â””â”€ page.tsx           # App shell (Sidebar + MainPanel)
   â”‚  â”œâ”€ layout.tsx            # Wraps Redux Provider
   â”‚  â””â”€ page.tsx              # Landing page
   â”‚
   â”œâ”€ components/
   â”‚  â”œâ”€ chat-input.tsx
   â”‚  â”œâ”€ main-panel.tsx
   â”‚  â”œâ”€ response-message.tsx
   â”‚  â”œâ”€ sidebar.tsx
   â”‚  â””â”€ icons.tsx
   â”‚
   â”œâ”€ constants/
   â”‚  â”œâ”€ frontend-constants.tsx
   â”‚
   â”œâ”€ features/
   â”‚  â””â”€ chat/
   â”‚     â”œâ”€ chat-slice.ts       # Redux slice (chats, selection, clarify, loading)
   â”‚     â””â”€ chat-thunks.ts      # sendMessage() async flow
   â”‚
   â”œâ”€ lib/
   â”‚  â””â”€ gemini-client.ts       # classify â†’ correct â†’ answer â†’ clarify helpers
   â”‚
   â”œâ”€ styles/
   â”‚  â”œâ”€ components/           # *.module.css for components
   â”‚  â”‚  â”œâ”€ chat-input.module.css
   â”‚  â”‚  â”œâ”€ main-panel.module.css
   â”‚  â”‚  â”œâ”€ response-message.module.css
   â”‚  â”‚  â””â”€ sidebar.module.css
   â”‚  â””â”€ pages/                # *.module.css for pages
   â”‚     â”œâ”€ home-page.module.css
   â”‚     â””â”€ landing-page.module.css
   â”‚
   â””â”€ store.ts                 # configureStore (adds chat reducer)
```

---

## 1ï¸âƒ£ Requirements

- **Node.js 18+**
- **A Google Gemini API key** (get it from [Google AI Studio](https://aistudio.google.com/app/apikey))

---

## 2ï¸âƒ£ Install

```bash
npm i
# or: yarn / pnpm
```

---

## 3ï¸âƒ£ Environment Setup

Create a `.env.local` file in the project root:

```
GEMINI_API_KEY=your_api_key_here
```

> The key is only read server-side by the Next.js API route.

---

## 4ï¸âƒ£ Run in Development

```bash
npm run dev
```

Then open [http://localhost:3000](http://localhost:3000) in your browser.

---

## ğŸ”‘ API Route (Gemini)

The API endpoint at:  
`src/app/api/gemini/route.ts`  
accepts POST requests with:

```json
{ "prompt": "your text", "model": "gemini-2.5-flash | gemini-1.5-flash" }
```

and returns:

```json
{ "text": "model response", "modelUsed": "gemini-2.5-flash" }
```

- The route normalizes SDK responses and **retries/falls back** if a model is UNAVAILABLE / 503.

#### Models used

- **gemini-2.5-flash** (primary generation)
- **gemini-1.5-flash** (classification, typo-correction, fallback generation)

---

## ğŸ§  Chat Flow (Send button)

Implemented across `chatThunks.ts` and `lib/geminiClient.ts`:

- **Optimistic UI** â€“ your message appears immediately.
- **Clarify mode** (if last assistant message starts with `Clarify:`):

  - Combine the original question + clarify question + your short reply
  - Ask again â†’ chain clarifications if needed; otherwise show final answer

- **Normal mode**:
  - Classify (is it coding-related?) â†’ if not, show a friendly non-code message
  - Correct typos for technical terms
  - Answer (2.5 â†’ 1.5 with retries/fallback)
  - If weak/ambiguous, return a single `Clarify:` line

---

## ğŸ§­ Redux State

- `chats: ChatSession[]`
- `currentChatId: string | null`
- `isLoading: boolean`
- `pendingClarify: { basePrompt: string; question: string } | null`

**Reducers**

- `newChat()` â€” create & select a fresh chat
- `selectChat(id)` â€” switch active chat
- `addMessage({ chatId, message })` â€” append messages
- `setTitle({ chatId, title })` â€” auto/rename chat title
- `setPendingClarify(ctx | null)` â€” store/clear clarify context
- `deleteChat(id) / deleteAllChats()` â€” remove chats

**Thunk**

- `sendMessage({ prompt })` â€” runs the full sequence above

---

## ğŸ§© UI Components

- **Sidebar** â€” chat list (uniform tiles), â€œNew Chatâ€, delete chat
- **MainPanel** â€” header, scrollable messages (auto-scroll), spinner, input dock
- **ChatInput** â€” autosizing textarea; Enter / Shift+Enter
- **ResponseMessage** â€” Markdown + inline/fenced code with Prism oneDark

---

## ğŸ›¡ Security

- **Keep `GEMINI_API_KEY` in `.env.local` (server-side only).**
- Avoid logging sensitive prompts/responses in production.

---

## ğŸ§ª Troubleshooting

- **â€œCould not load the default credentialsâ€**  
  Ensure `GEMINI_API_KEY` is set; restart the dev server.

- **503 / UNAVAILABLE**  
  The route already retries and falls back; try again shortly.

- **Type issues with react-syntax-highlighter**  
  Use ESM Prism imports as in `response-message.tsx`:
  ```ts
  import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';
  import { oneDark } from 'react-syntax-highlighter/dist/esm/styles/prism';
  ```

---

## ğŸ“¦ Scripts

- `npm run dev`     â€“ start dev server
- `npm run build`   â€“ production build
- `npm run start`   â€“ start prod server
- `npm run lint`    â€“ lint

---

Enjoy chatting! âœ¨
